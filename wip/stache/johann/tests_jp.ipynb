{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c85d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d86ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmap0 = cv2.imread(\"../inputs/mmap0.png\")\n",
    "mmap1 = cv2.imread(\"../inputs/mmap1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85651ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusiooon = cv2.addWeighted(mmap0, 0.5, mmap1, 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fusiooon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7f033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_fg(img):\n",
    "    gimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh1 = cv2.threshold(gimg,110,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    boxed = cv2.boxFilter(thresh1, -1, (40, 40), normalize=False)\n",
    "    alpha = cv2.blur(boxed, (11, 11))\n",
    "    alpha = alpha.reshape(*alpha.shape, 1).astype('float32')/255\n",
    "\n",
    "    fg = (img*alpha).astype('uint8')\n",
    "    composed = cv2.addWeighted(img, 0.2, fg, 0.8, 0)\n",
    "    return composed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f33fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmap0 = enhance_fg(mmap0)\n",
    "mmap1 = enhance_fg(mmap1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f41743",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = cv2.imread(\"../inputs/cross.png\")\n",
    "plt.imshow(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = cv2.AgastFeatureDetector.create(threshold=40)\n",
    "detector = cv2.KAZE.create()\n",
    "descriptor = cv2.SIFT_create()\n",
    "\n",
    "kps = detector.detect(cross, None)\n",
    "len(kps)\n",
    "\n",
    "kps, feat = descriptor.compute(cross, kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5096a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.drawKeypoints(cross, kps[1:2], None, color=(0,255,0), flags=0)\n",
    "plt.imshow(img2), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb930977",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mmap0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "brisk = cv2.BRISK.create(thresh=100)\n",
    "\n",
    "agast = cv2.AgastFeatureDetector.create()\n",
    "\n",
    "img = mmap0.copy()\n",
    "\n",
    "kp = agast.detect(img,None)\n",
    "# compute the descriptors with ORB\n",
    "\n",
    "center = np.float32(mmap0.shape[1::-1]) / 2\n",
    "kp = [pt for pt in kp if np.linalg.norm(pt.pt - center) < 115]\n",
    "\n",
    "kp, des = brisk.compute(img, kp)\n",
    "# draw only keypoints location,not size and orientation\n",
    "img2 = cv2.drawKeypoints(img, kp, None, color=(0,255,0), flags=0)\n",
    "plt.imshow(img2), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d70011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c161399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kp_description(frame, filter_radius=False, use_binary=False):\n",
    "    descriptor = cv2.KAZE.create() if use_binary else cv2.KAZE.create(upright=True)#cv2.SIFT_create()\n",
    "\n",
    "    detector = cv2.KAZE.create(upright=True)\n",
    "\n",
    "    kp1 = detector.detect(frame)\n",
    "    \n",
    "    if filter_radius:\n",
    "        kp1 = filter_kp(kp1, frame)\n",
    "    \n",
    "    kp1, des1 = descriptor.compute(frame, kp1)\n",
    "\n",
    "    return kp1, des1\n",
    "\n",
    "def kp_matching(des1, des2, ann=False, k=2, use_binary=False):\n",
    "    if ann: #WARNING Not finished\n",
    "        FLANN_INDEX_LSH = 6\n",
    "        index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                       table_number = 6, # 12\n",
    "                       key_size = 12,     # 20\n",
    "                       multi_probe_level = 1) #2\n",
    "        search_params = dict(checks=50)\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(descriptors0, descriptors1, k=k)\n",
    "    else: #slower but not approximate\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING if use_binary else cv2.NORM_L2)\n",
    "        matches = bf.knnMatch(des1,des2,k=k)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46adbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_kp(kp, img, radius=115):\n",
    "    center = np.float32(img.shape[1::-1]) / 2\n",
    "    return [pt for pt in kp if np.linalg.norm(pt.pt - center) < 115]\n",
    "\n",
    "def binary_kp_description(frame1, frame2, filter_radius=True, use_orb=False):\n",
    "    algo = cv2.ORB_create() if use_orb else cv2.BRISK.create(thresh=50)\n",
    "    algo = cv2.SIFT_create()\n",
    "    detector = cv2.KAZE.create(upright=True)\n",
    "    \n",
    "    kp1 = detector.detect(frame1,None)\n",
    "    kp2 = detector.detect(frame2,None)\n",
    "    \n",
    "    if filter_radius:\n",
    "        kp1 = filter_kp(kp1, frame1)\n",
    "        kp2 = filter_kp(kp2, frame2)\n",
    "    \n",
    "    kp1, des1 = algo.compute(frame1, kp1)\n",
    "    kp2, des2 = algo.compute(frame2, kp2)\n",
    "\n",
    "    return kp1, des1, kp2, des2\n",
    "\n",
    "def binary_kp_matching(des1, des2, ann=False, k=2):\n",
    "    if ann: #WARNING NEEDS testing\n",
    "        FLANN_INDEX_LSH = 6\n",
    "        index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                       table_number = 6, # 12\n",
    "                       key_size = 12,     # 20\n",
    "                       multi_probe_level = 1) #2\n",
    "        search_params = dict(checks=50)\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(descriptors0, descriptors1, k=k)\n",
    "    else: #slower but not approximate\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "        matches = bf.knnMatch(des1,des2,k=k)\n",
    "    return matches\n",
    "\n",
    "def filter_matches(matches, ratio_test=False):\n",
    "    if ratio_test:\n",
    "        good = []\n",
    "        for m, n in matches: #Lowe's SIFT value may not be relevant for binary descriptors\n",
    "            if m.distance < 0.9 * n.distance:\n",
    "                good.append(m)\n",
    "        return good\n",
    "    else:\n",
    "        return [m[0] for m in matches]\n",
    "    \n",
    "def draw_matches(frame1, kp1, frame2, kp2, good, matchesMask=None):\n",
    "    draw_params = dict(matchColor=(0, 255, 0),  # draw matches in green color\n",
    "                       singlePointColor=None,\n",
    "                       matchesMask=matchesMask,  # draw only inliers\n",
    "                       flags=2)\n",
    "\n",
    "    comparison = cv2.drawMatches(frame1, kp1, frame2, kp2, good, None, **draw_params)\n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ffd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_binary = False\n",
    "\n",
    "cross = cv2.imread(\"../inputs/cross.png\")\n",
    "\n",
    "cross_kp, cross_des = kp_description(cross, use_binary=use_binary)\n",
    "\n",
    "kp1, des1 = kp_description(mmap0, use_binary=use_binary)\n",
    "kp2, des2 = kp_description(mmap1, use_binary=use_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca1b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.drawKeypoints(mmap0, kp1, None, color=(0,255,0), flags=0)\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4644619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_with_cross(cross_des, kp1, des1):\n",
    "\n",
    "    matches = kp_matching(cross_des, des1, k=20, use_binary=use_binary)\n",
    "    kp = [kp1[m.trainIdx] for m in matches[0]]\n",
    "    des = [des1[m.trainIdx] for m in matches[0]]\n",
    "    return kp, np.vstack(des)  #can do better than 0\n",
    "\n",
    "kp1, des1 = filter_with_cross(cross_des, kp1, des1)\n",
    "kp2, des2 = filter_with_cross(cross_des, kp2, des2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c829faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.drawKeypoints(mmap0, kp1, None, color=(0,255,0), flags=0)\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.drawKeypoints(mmap1, kp2, None, color=(0,255,0), flags=0)\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3081443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = kp_matching(des1, des2, k=2, use_binary=use_binary)\n",
    "matches = filter_matches(matches, ratio_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad038d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = draw_matches(mmap0, kp1, mmap1, kp2, matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7955f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "m, _ = cv2.estimateAffinePartial2D(src_pts, dst_pts, method=cv2.LMEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035cc986",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward = cv2.warpAffine(mmap0, m, mmap1.shape[1::-1])\n",
    "plt.imshow(cv2.addWeighted(mmap1, 0.5, forward, 0.5, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e41686",
   "metadata": {},
   "outputs": [],
   "source": [
    "backward = cv2.warpAffine(mmap1, m, mmap0.shape[1::-1], flags=cv2.WARP_INVERSE_MAP)\n",
    "plt.imshow(cv2.addWeighted(mmap0, 0.5, backward, 0.5, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e4f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mp = np.zeros([3,3])\n",
    "Mp[:2, :3] = m\n",
    "Mp[2, 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d376e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mmap1.copy()\n",
    "\n",
    "fw_pts = cv2.perspectiveTransform(src_pts, Mp)\n",
    "\n",
    "for p1, p2 in zip(fw_pts.reshape(-1, 2), dst_pts.reshape(-1, 2)):\n",
    "    cv2.circle(out, tuple(p1.astype('int')), 3, (0, 0, 255))\n",
    "    cv2.circle(out, tuple(p2.astype('int')), 4, (255, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384fa35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = np.float32([0, 0]).reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = np.float32(mmap0.shape[1::-1]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57240ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_center = cv2.perspectiveTransform(center.reshape(-1, 1, 2), Mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c3f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = new_center - center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064db8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "center + delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce6cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8419731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = np.float32([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65395eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6341428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc + delta.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b286925",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d05f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(540, 960, 3) (301, 790, 3) (480, 640, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10554d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 960 / (790+640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s*480, s*640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c06c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s*301, s*790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92baf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "render = np.zeros([540+322,960,3])\n",
    "render[:540,:960,:] = ref\n",
    "render[540:742,:530] = cv2.resize(comparison, (202,530))\n",
    "render[540:,530:] = cv2.resize(img, (322,430))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99908b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
